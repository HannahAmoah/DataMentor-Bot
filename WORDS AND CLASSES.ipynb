{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6581b5a7-9119-451f-b26a-8b1c1762d608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ words.pkl and classes.pkl have been created successfully!\n",
      "Total words: 75, Total classes: 9\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Load intents.json\n",
    "with open(\"intents.json\", \"r\") as file:\n",
    "    intents = json.load(file)\n",
    "\n",
    "words = []     # Stores all words\n",
    "classes = []   # Stores all intent categories\n",
    "ignore_words = [\"?\", \"!\", \".\", \",\"]  # Words to ignore\n",
    "\n",
    "# Extract words and intents\n",
    "for intent in intents[\"intents\"]:\n",
    "    for pattern in intent[\"examples\"]:  # Use 'examples' instead of 'patterns'\n",
    "        word_list = nltk.word_tokenize(pattern)  # Tokenize each example sentence\n",
    "        words.extend(word_list)  # Add words to the words list\n",
    "    if intent[\"intent\"] not in classes:\n",
    "        classes.append(intent[\"intent\"])  # Store intent name\n",
    "\n",
    "# Lemmatize & remove duplicates\n",
    "words = [lemmatizer.lemmatize(word.lower()) for word in words if word not in ignore_words]\n",
    "words = sorted(set(words))  # Remove duplicates and sort\n",
    "\n",
    "# Sort classes\n",
    "classes = sorted(set(classes))  # Ensure uniqueness and sorting\n",
    "\n",
    "# Save words.pkl\n",
    "with open(\"words.pkl\", \"wb\") as file:\n",
    "    pickle.dump(words, file)\n",
    "\n",
    "# Save classes.pkl\n",
    "with open(\"classes.pkl\", \"wb\") as file:\n",
    "    pickle.dump(classes, file)\n",
    "\n",
    "print(\"✅ words.pkl and classes.pkl have been created successfully!\")\n",
    "print(f\"Total words: {len(words)}, Total classes: {len(classes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9081469-3a34-4f2b-ab02-91d1f556f1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in words.pkl: 75\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load words.pkl\n",
    "with open(\"words.pkl\", \"rb\") as file:\n",
    "    words = pickle.load(file)\n",
    "\n",
    "print(f\"Total words in words.pkl: {len(words)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e2ddaf-f198-4fc4-bd87-5bddc4d57c02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
